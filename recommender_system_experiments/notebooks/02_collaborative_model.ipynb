{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9230cbc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -q implicit scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "76ef5f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from implicit.als import AlternatingLeastSquares\n",
    "from scipy.sparse import csr_matrix\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict, Counter\n",
    "from itertools import combinations\n",
    "import random\n",
    "import math\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2ebf9510",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path = \"processed/01_filtered/\"\n",
    "\n",
    "with open(Path(input_path) / \"filtered_playlists.pkl\", \"rb\") as f:\n",
    "    playlists = pickle.load(f)  # list of lists of track_uris\n",
    "\n",
    "with open(Path(input_path) / \"valid_tracks.pkl\", \"rb\") as f:\n",
    "    valid_tracks_dict = pickle.load(f)  # dict from track_uri -> metadata dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7e21dbff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filtering playlists: 100%|██████████| 774682/774682 [00:03<00:00, 249569.11it/s]\n"
     ]
    }
   ],
   "source": [
    "def filter_valid_tracks(playlists, valid_tracks):\n",
    "    filtered = []\n",
    "    for pl in tqdm(playlists, total=len(playlists), desc=\"Filtering playlists\"):\n",
    "        filtered_tracks = [t for t in pl['tracks'] if t in valid_tracks]\n",
    "        filtered.append({'name': pl['name'], 'tracks': filtered_tracks})\n",
    "    return filtered\n",
    "\n",
    "filtered_playlists = filter_valid_tracks(playlists, valid_tracks_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a0182a40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'Baile', 'tracks': ['spotify:track:3ZFTkvIE7kyPt6Nu3PEa7V']}\n"
     ]
    }
   ],
   "source": [
    "print(filtered_playlists[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d8c4eaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train playlists: 619745, Test playlists: 154937\n"
     ]
    }
   ],
   "source": [
    "# Train/test split (80/20)\n",
    "random.seed(42)\n",
    "idxs = list(range(len(filtered_playlists)))\n",
    "random.shuffle(idxs)\n",
    "split_idx = int(0.8 * len(idxs))\n",
    "\n",
    "train_idxs = idxs[:split_idx]\n",
    "test_idxs = idxs[split_idx:]\n",
    "\n",
    "train_playlists = [filtered_playlists[i] for i in train_idxs]\n",
    "test_playlists = [filtered_playlists[i] for i in test_idxs]\n",
    "\n",
    "print(f\"Train playlists: {len(train_playlists)}, Test playlists: {len(test_playlists)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d2870637",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building inverted index: 100%|██████████| 619745/619745 [00:01<00:00, 321055.90it/s]\n"
     ]
    }
   ],
   "source": [
    "# Build inverted index from training data only\n",
    "track_to_playlists = defaultdict(set)\n",
    "for pid, pl in tqdm(enumerate(train_playlists), total=len(train_playlists), desc=\"Building inverted index\"):\n",
    "    for track in pl['tracks']:\n",
    "        track_to_playlists[track].add(pid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1060451a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recommendation function\n",
    "def find_similar_playlists(query_tracks, track_to_pl, max_neighbors=500):\n",
    "    candidate_counts = Counter()\n",
    "    for track in query_tracks:\n",
    "        candidate_counts.update(track_to_pl.get(track, set()))\n",
    "    most_common = candidate_counts.most_common(max_neighbors)\n",
    "    similar_pids = [pid for pid, count in most_common]\n",
    "    return similar_pids\n",
    "\n",
    "def recommend_tracks(query_playlist, train_playlists, track_to_pl, top_k=100, max_neighbors=500):\n",
    "    query_tracks = query_playlist['tracks']\n",
    "    similar_pids = find_similar_playlists(query_tracks, track_to_pl, max_neighbors=max_neighbors)\n",
    "    track_counter = Counter()\n",
    "    for pid in similar_pids:\n",
    "        pl = train_playlists[pid]\n",
    "        track_counter.update(pl['tracks'])\n",
    "    existing_tracks = set(query_tracks)\n",
    "    recommendations = [t for t, _ in track_counter.most_common() if t not in existing_tracks]\n",
    "    return recommendations[:top_k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ae50f142",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Evaluation metrics\n",
    "def recall_at_k(true_tracks, pred_tracks, k):\n",
    "    true_set = set(true_tracks)\n",
    "    pred_set = set(pred_tracks[:k])\n",
    "    if not true_set:\n",
    "        return 0.0\n",
    "    return len(true_set & pred_set) / len(true_set)\n",
    "\n",
    "def ndcg_at_k(true_tracks, pred_tracks, k):\n",
    "    true_set = set(true_tracks)\n",
    "    dcg = 0.0\n",
    "    idcg = 0.0\n",
    "    for i in range(k):\n",
    "        if i < len(pred_tracks) and pred_tracks[i] in true_set:\n",
    "            dcg += 1 / math.log2(i + 2)\n",
    "    # Ideal DCG: all true tracks ranked perfectly\n",
    "    for i in range(min(len(true_tracks), k)):\n",
    "        idcg += 1 / math.log2(i + 2)\n",
    "    return dcg / idcg if idcg > 0 else 0.0\n",
    "\n",
    "# Prepare test data: split test playlists into input (partial) and target (held-out tracks)\n",
    "def split_test_playlist(pl, test_ratio=0.3, min_heldout=1):\n",
    "    tracks = pl['tracks']\n",
    "    n = len(tracks)\n",
    "    if n < 2:\n",
    "        return None, None\n",
    "    n_heldout = max(int(n * test_ratio), min_heldout)\n",
    "    heldout = tracks[-n_heldout:]\n",
    "    input_tracks = tracks[:-n_heldout]\n",
    "    if len(input_tracks) == 0:\n",
    "        # fallback: keep at least one track in input\n",
    "        input_tracks = tracks[:1]\n",
    "        heldout = tracks[1:]\n",
    "    return input_tracks, heldout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "70fd40e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting evaluation on test set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating playlists: 100%|██████████| 1000/1000 [00:22<00:00, 45.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall@100: 0.6890\n",
      "NDCG@100: 0.3072\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "recall_scores = []\n",
    "ndcg_scores = []\n",
    "top_k = 100\n",
    "\n",
    "print(\"Starting evaluation on test set...\")\n",
    "for pl in tqdm(random.sample(test_playlists, k=1000), total=1000, desc=\"Evaluating playlists\"):\n",
    "    input_tracks, heldout_tracks = split_test_playlist(pl)\n",
    "    if input_tracks is None or heldout_tracks is None or len(heldout_tracks) == 0:\n",
    "        continue\n",
    "    input_pl = {'name': pl['name'], 'tracks': input_tracks}\n",
    "    preds = recommend_tracks(input_pl, train_playlists, track_to_playlists, top_k=top_k)\n",
    "    recall_scores.append(recall_at_k(heldout_tracks, preds, top_k))\n",
    "    ndcg_scores.append(ndcg_at_k(heldout_tracks, preds, top_k))\n",
    "\n",
    "print(f\"Recall@{top_k}: {np.mean(recall_scores):.4f}\")\n",
    "print(f\"NDCG@{top_k}: {np.mean(ndcg_scores):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51c28f14",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "recommender_system",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
