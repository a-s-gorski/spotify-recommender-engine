{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c5fd7d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import re\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "613f7ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path = \"processed/01_filtered/\"\n",
    "\n",
    "with open(Path(input_path) / \"filtered_playlists.pkl\", \"rb\") as f:\n",
    "    playlists = pickle.load(f)  # list of lists of track_uris\n",
    "\n",
    "with open(Path(input_path) / \"valid_tracks.pkl\", \"rb\") as f:\n",
    "    valid_tracks_dict = pickle.load(f)  # dict from track_uri -> metadata dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e35905a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filtering playlists: 100%|██████████| 996829/996829 [00:36<00:00, 27632.62it/s]\n"
     ]
    }
   ],
   "source": [
    "def filter_valid_tracks(playlists, valid_tracks):\n",
    "    filtered = []\n",
    "    for pl in tqdm(playlists, total=len(playlists), desc=\"Filtering playlists\"):\n",
    "        filtered_tracks = [t for t in pl['tracks'] if t in valid_tracks]\n",
    "        filtered.append({'name': pl['name'], 'tracks': filtered_tracks})\n",
    "    return filtered\n",
    "\n",
    "filtered_playlists = filter_valid_tracks(playlists, valid_tracks_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b6a46707",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'Baile',\n",
       " 'tracks': ['spotify:track:4Uc6BcPeBKfZUlX6jhumGv',\n",
       "  'spotify:track:0Hf4aIJpsN4Os2f0y0VqWl',\n",
       "  'spotify:track:2eqDUxbd0JPEhNrJdPlHLs',\n",
       "  'spotify:track:4LXDHgBC1mbz3uoehYxH9b',\n",
       "  'spotify:track:4Y7XAxTANhu3lmnLAzhWJW',\n",
       "  'spotify:track:3ZFTkvIE7kyPt6Nu3PEa7V',\n",
       "  'spotify:track:1eAj7zEFiX24oYScyIP8aO',\n",
       "  'spotify:track:3XVCXTxYPptsMLwO463btY',\n",
       "  'spotify:track:0UGJsRE9T0r6sIMR3mQzUW',\n",
       "  'spotify:track:6JFBgJECPfDjzVLJ65jqm7',\n",
       "  'spotify:track:4MK30zdOpWTvpE6UoJukIp',\n",
       "  'spotify:track:4fIk8LQ1hojY8ZfFQi419y',\n",
       "  'spotify:track:32lm3769IRfcnrQV11LO4E']}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_playlists[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2d600927",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_playlists = [p for p in filtered_playlists if len(p['tracks']) >= 5]\n",
    "\n",
    "train_playlists, test_playlists = train_test_split(filtered_playlists, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3cefd5a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_names = [p['name'] for p in train_playlists]\n",
    "train_tracks = [p['tracks'] for p in train_playlists]\n",
    "\n",
    "vectorizer = TfidfVectorizer(max_features=500, stop_words='english', lowercase=True, token_pattern=r'\\b\\w+\\b')\n",
    "name_vectors = vectorizer.fit_transform(train_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b4281f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def recommend_tracks_from_name(name, k=10, n_neighbors=5):\n",
    "    query_vec = vectorizer.transform([name])\n",
    "    sims = cosine_similarity(query_vec, name_vectors)[0]\n",
    "    top_idx = sims.argsort()[::-1][:n_neighbors]\n",
    "\n",
    "    recommended_tracks = []\n",
    "    for idx in top_idx:\n",
    "        recommended_tracks.extend(train_tracks[idx])\n",
    "\n",
    "    return list(dict.fromkeys(recommended_tracks))[:k]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2eaa924d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from tqdm import tqdm\n",
    "from multiprocessing import Pool, cpu_count\n",
    "from functools import partial\n",
    "import random\n",
    "\n",
    "def precision_at_k(y_true, y_pred, k=10):\n",
    "    return len(set(y_true) & set(y_pred[:k])) / k\n",
    "\n",
    "def _evaluate_batch(batch_indices, test_playlists, test_vectors, train_vectors, train_track_lists, k, n_neighbors):\n",
    "    precisions = []\n",
    "\n",
    "    sims = cosine_similarity(test_vectors[batch_indices], train_vectors)\n",
    "\n",
    "    for i, idx in enumerate(batch_indices):\n",
    "        true_tracks = [t for t in test_playlists[idx]['tracks'] if t in valid_tracks_dict]\n",
    "        if not true_tracks:\n",
    "            continue\n",
    "\n",
    "        top_idx = sims[i].argsort()[::-1][:n_neighbors]\n",
    "\n",
    "        # Collect recommended tracks from top similar playlists\n",
    "        pred_tracks = []\n",
    "        for tid in top_idx:\n",
    "            pred_tracks.extend(train_track_lists[tid])\n",
    "        pred_tracks = list(dict.fromkeys(pred_tracks))[:k]\n",
    "\n",
    "        precisions.append(precision_at_k(true_tracks, pred_tracks, k))\n",
    "\n",
    "    return precisions\n",
    "\n",
    "def parallel_sparse_evaluate(test_playlists, vectorizer, train_vectors, train_track_lists, \n",
    "                             k=10, n_neighbors=5, batch_size=512, subsample=None, num_workers=None):\n",
    "    if subsample is not None:\n",
    "        test_playlists = random.sample(test_playlists, min(subsample, len(test_playlists)))\n",
    "\n",
    "    test_names = [p['name'] for p in test_playlists]\n",
    "    test_vectors = vectorizer.transform(test_names)\n",
    "\n",
    "    indices = list(range(len(test_playlists)))\n",
    "    batches = [indices[i:i+batch_size] for i in range(0, len(indices), batch_size)]\n",
    "\n",
    "    num_workers = num_workers or min(cpu_count(), 8)\n",
    "\n",
    "    with Pool(num_workers) as pool:\n",
    "        func = partial(_evaluate_batch,\n",
    "                       test_playlists=test_playlists,\n",
    "                       test_vectors=test_vectors,\n",
    "                       train_vectors=train_vectors,\n",
    "                       train_track_lists=train_track_lists,\n",
    "                       k=k,\n",
    "                       n_neighbors=n_neighbors)\n",
    "        \n",
    "        all_precisions = list(tqdm(pool.imap(func, batches), total=len(batches)))\n",
    "    \n",
    "    # Flatten\n",
    "    precisions = [p for batch in all_precisions for p in batch]\n",
    "\n",
    "    return np.mean(precisions) if precisions else 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "04e3a9f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from scipy.sparse import csr_matrix\n",
    "\n",
    "# train_vectors = name_vectors  # already sparse\n",
    "# train_track_lists = np.array(train_tracks, dtype=object)\n",
    "\n",
    "# score = parallel_sparse_evaluate(\n",
    "#     test_playlists=test_playlists,\n",
    "#     vectorizer=vectorizer,\n",
    "#     train_vectors=train_vectors,\n",
    "#     train_track_lists=train_track_lists,\n",
    "#     k=10,\n",
    "#     n_neighbors=3,\n",
    "#     batch_size=1024,\n",
    "#     subsample=10000,           # Try 5k test playlists\n",
    "#     num_workers=cpu_count()             # You can increase if needed\n",
    "# )\n",
    "\n",
    "# print(f\"Parallel Precision@10: {score:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f742ebd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['La Bala', 'Vivir Mi Vida', 'Periodico De Ayer', 'El Cantante', 'La Vida Es Un Carnaval', 'Bailando - English Version', 'Fireball', 'La Tortura', \"Let's Get Loud\", 'I Know You Want Me (Calle Ocho)']\n",
      "['29 #Strafford APTS', 'Wake Up Your Saints', 'Cruel', 'Carrie & Lowell', 'Dark Days', 'Hey Mami', 'Caught Me Thinkin', \"We're on Our Way\", 'Black Sun', 'Hag']\n",
      "['State Of My Head', 'Gotta Get Away', 'Can You Feel My Heart', 'Sleepwalking', 'Deathbeds', 'True Friends', 'Life Is Beautiful', 'This Is Gonna Hurt', 'Call Me', 'Better Version']\n",
      "['Power Trip', 'So Good', '6 Foot 7 Foot', '0 To 100 / The Catch Up', 'HYFR (Hell Ya Fucking Right)', 'Work Out', 'Crooked Smile', 'Swimming Pools (Drank) - Extended Version', 'REVOFEV', \"Coastin'\"]\n"
     ]
    }
   ],
   "source": [
    "print(list(map(lambda uri: valid_tracks_dict.get(uri, {}).get('track_name', 'unknown_name') ,(recommend_tracks_from_name(\"Fiesta Latina\", k=10)))))\n",
    "print(list(map(lambda uri: valid_tracks_dict.get(uri, {}).get('track_name', 'unknown_name') ,(recommend_tracks_from_name(\"Morning Chill\", k=10)))))\n",
    "print(list(map(lambda uri: valid_tracks_dict.get(uri, {}).get('track_name', 'unknown_name') ,(recommend_tracks_from_name(\"Rock\", k=10)))))\n",
    "print(list(map(lambda uri: valid_tracks_dict.get(uri, {}).get('track_name', 'unknown_name') ,(recommend_tracks_from_name(\"Dark\", k=10)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5d4ad9b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "756a99aa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "recommender_system",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
